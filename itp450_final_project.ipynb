{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78599ade-681d-429b-a386-4a70f812a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaf97f4-5785-4d47-b921-6f188c110a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 12:38:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              35W / 250W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              37W / 250W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1727240-cd03-4611-8040-995c04e6d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_CHANNELS = 3\n",
    "INPUT_IMAGE_DIM = 32\n",
    "\n",
    "CONV_LAYER1_OUTPUT_CHANNELS = 256\n",
    "CONV_LAYER1_KERNEL_SIZE = 5\n",
    "CONV_LAYER1_STRIDE = 1\n",
    "CONV_LAYER1_PADDING = 0\n",
    "\n",
    "CONV_MAX_POOL_1_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_1_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_1_STRIDE_SIZE = 2\n",
    "\n",
    "CONV_LAYER2_OUTPUT_CHANNELS = 128\n",
    "CONV_LAYER2_KERNEL_SIZE = 5\n",
    "CONV_LAYER2_STRIDE = 1\n",
    "CONV_LAYER2_PADDING = 2\n",
    "\n",
    "CONV_MAX_POOL_2_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_2_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_2_STRIDE_SIZE = 2\n",
    "\n",
    "CONV_LAYER3_OUTPUT_CHANNELS = 256\n",
    "CONV_LAYER3_KERNEL_SIZE = 5\n",
    "CONV_LAYER3_STRIDE = 1\n",
    "CONV_LAYER3_PADDING = 2\n",
    "\n",
    "CONV_MAX_POOL_3_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_3_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_3_STRIDE_SIZE = 1\n",
    "\n",
    "DROP_OUT_RATE = 0.25\n",
    "\n",
    "LINEAR_LAYER_1_OUTPUT_SIZE = 16834\n",
    "LINEAR_LAYER_2_OUTPUT_SIZE = 512\n",
    "\n",
    "# NUMBER OF CLASSES\n",
    "LINEAR_LAYER_3_OUTPUT_SIZE = 10 # 10 for the amount of classes that are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e727f3-45db-4aba-a7aa-14faf663d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class serialized_CNN_Model(nn.Module):\n",
    "    def __init__(self, num_gpus):\n",
    "        super(serialized_CNN_Model, self).__init__()\n",
    "\n",
    "        # CONV2D LAYER1 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer1 = nn.Conv2d(INPUT_IMAGE_CHANNELS, CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER1_KERNEL_SIZE, CONV_LAYER1_STRIDE, CONV_LAYER1_PADDING)\n",
    "        self.image_dimension = (INPUT_IMAGE_DIM - ((CONV_LAYER1_KERNEL_SIZE) - (2 * CONV_LAYER1_PADDING)))//CONV_LAYER1_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER1_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 1, Change in image dimensions\n",
    "        self.maxPooling1 = nn.MaxPool2d(CONV_MAX_POOL_1_KERNEL_SIZE, CONV_MAX_POOL_1_STRIDE_SIZE, CONV_MAX_POOL_1_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_1_KERNEL_SIZE) - (2 * CONV_MAX_POOL_1_PADDING_SIZE)))//CONV_MAX_POOL_1_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        \n",
    "        # CONV2D LAYER2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer2 = nn.Conv2d(CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER2_KERNEL_SIZE, CONV_LAYER2_STRIDE, CONV_LAYER2_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER2_KERNEL_SIZE) - (2 * CONV_LAYER2_PADDING)))//CONV_LAYER2_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER2_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.maxPooling2 = nn.MaxPool2d(CONV_MAX_POOL_2_KERNEL_SIZE, CONV_MAX_POOL_2_STRIDE_SIZE, CONV_MAX_POOL_2_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_2_KERNEL_SIZE) - (2 * CONV_MAX_POOL_2_PADDING_SIZE)))//CONV_MAX_POOL_2_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        \n",
    "        # CONV2D LAYER 3 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer3 = nn.Conv2d(CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER3_OUTPUT_CHANNELS, CONV_LAYER3_KERNEL_SIZE, CONV_LAYER3_STRIDE, CONV_LAYER3_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER3_KERNEL_SIZE) - (2 * CONV_LAYER3_PADDING)))//CONV_LAYER3_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER3_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "        \n",
    "\n",
    "        # MAX POOLING LAYER 3 AND CHANGE IN IIMAGE DIMENSIONS\n",
    "        self.maxPooling3 = nn.MaxPool2d(CONV_MAX_POOL_3_KERNEL_SIZE, CONV_MAX_POOL_3_STRIDE_SIZE, CONV_MAX_POOL_3_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_3_KERNEL_SIZE) - (2 * CONV_MAX_POOL_3_PADDING_SIZE)))//CONV_MAX_POOL_3_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # Since we flatten the image after the CONV2D Layers, we need to calculate the size of the feature\n",
    "        # Vector going into the nn.Linear layer\n",
    "        self.fc1_input_size = self.image_dimension * self.image_dimension * self.image_channel_size\n",
    "        \n",
    "        # Fully connected Layers\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        print(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        \n",
    "        self.fc2 = nn.Linear(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "        print(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "\n",
    "        \n",
    "        self.fc3 = nn.Linear(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "        print(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "\n",
    "\n",
    "        self.layers = [self.conv_layer1, self.maxPooling1, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.conv_layer2, self.maxPooling2, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.conv_layer3, self.maxPooling3, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       torch.nn.Flatten(),\n",
    "                       self.fc1, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.fc2, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.fc3,\n",
    "                      ]\n",
    "        \n",
    "        self.model_layers = [torch.nn.Sequential(*self.layers)]\n",
    "\n",
    "        self.model_layers[0].to(f'cuda:{0}')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for i in range(len(self.model_layers)):\n",
    "            x = x.to(f'cuda:{i}')\n",
    "            x = self.model_layers[i](x)\n",
    "\n",
    "        return x.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9435f15-62d9-4665-925e-a048f92efa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline_parallel_CNN_Model(nn.Module):\n",
    "    def __init__(self, num_gpus):\n",
    "        super(Pipeline_parallel_CNN_Model, self).__init__()\n",
    "\n",
    "        self.num_gpus = num_gpus\n",
    "        \n",
    "        # CONV2D LAYER1 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer1 = nn.Conv2d(INPUT_IMAGE_CHANNELS, CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER1_KERNEL_SIZE, CONV_LAYER1_STRIDE, CONV_LAYER1_PADDING)\n",
    "        self.image_dimension = (INPUT_IMAGE_DIM - ((CONV_LAYER1_KERNEL_SIZE) - (2 * CONV_LAYER1_PADDING)))//CONV_LAYER1_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER1_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 1, Change in image dimensions\n",
    "        self.maxPooling1 = nn.MaxPool2d(CONV_MAX_POOL_1_KERNEL_SIZE, CONV_MAX_POOL_1_STRIDE_SIZE, CONV_MAX_POOL_1_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_1_KERNEL_SIZE) - (2 * CONV_MAX_POOL_1_PADDING_SIZE)))//CONV_MAX_POOL_1_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        \n",
    "        # CONV2D LAYER2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer2 = nn.Conv2d(CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER2_KERNEL_SIZE, CONV_LAYER2_STRIDE, CONV_LAYER2_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER2_KERNEL_SIZE) - (2 * CONV_LAYER2_PADDING)))//CONV_LAYER2_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER2_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.maxPooling2 = nn.MaxPool2d(CONV_MAX_POOL_2_KERNEL_SIZE, CONV_MAX_POOL_2_STRIDE_SIZE, CONV_MAX_POOL_2_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_2_KERNEL_SIZE) - (2 * CONV_MAX_POOL_2_PADDING_SIZE)))//CONV_MAX_POOL_2_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        \n",
    "        # CONV2D LAYER 3 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer3 = nn.Conv2d(CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER3_OUTPUT_CHANNELS, CONV_LAYER3_KERNEL_SIZE, CONV_LAYER3_STRIDE, CONV_LAYER3_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER3_KERNEL_SIZE) - (2 * CONV_LAYER3_PADDING)))//CONV_LAYER3_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER3_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "        \n",
    "\n",
    "        # MAX POOLING LAYER 3 AND CHANGE IN IIMAGE DIMENSIONS\n",
    "        self.maxPooling3 = nn.MaxPool2d(CONV_MAX_POOL_3_KERNEL_SIZE, CONV_MAX_POOL_3_STRIDE_SIZE, CONV_MAX_POOL_3_PADDING_SIZE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_3_KERNEL_SIZE) - (2 * CONV_MAX_POOL_3_PADDING_SIZE)))//CONV_MAX_POOL_3_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "        \n",
    "\n",
    "        # Since we flatten the image after the CONV2D Layers, we need to calculate the size of the feature\n",
    "        # Vector going into the nn.Linear layer\n",
    "        self.fc1_input_size = self.image_dimension * self.image_dimension * self.image_channel_size\n",
    "        \n",
    "        # Fully connected Layers\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        print(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "        print(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "\n",
    "        \n",
    "        self.fc3 = nn.Linear(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "        print(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "\n",
    "\n",
    "        self.layers = [self.conv_layer1, self.maxPooling1, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.conv_layer2, self.maxPooling2, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.conv_layer3, self.maxPooling3, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       torch.nn.Flatten(),\n",
    "                       self.fc1, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.fc2, nn.Dropout(DROP_OUT_RATE), nn.ReLU(),\n",
    "                       self.fc3,\n",
    "                      ]\n",
    "\n",
    "        layer_len = len(self.layers)\n",
    "        split_stride = layer_len//self.num_gpus + 1\n",
    "        cuda_ind = 0\n",
    "        self.model_layers = []\n",
    "        \n",
    "        for i in range(0, layer_len, split_stride):\n",
    "            print(f'cuda:{cuda_ind}')\n",
    "            self.model_layers.append(nn.Sequential(*self.layers[i : i + split_stride]).to(f'cuda:{cuda_ind}'))\n",
    "            cuda_ind += 1\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for i in range(self.num_gpus):\n",
    "            x = x.to(f'cuda:{i}')\n",
    "            x = self.model_layers[i](x)\n",
    "\n",
    "        return x.to('cpu')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f63ecc2-a249-4888-9317-40f8269048d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Constants\n",
    "DATASET_SIZE = 50000\n",
    "\n",
    "# Training Hyperparams\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "# Optimizer Hyperparams\n",
    "LEARNING_RATE = 10e-3\n",
    "SGD_MOMENTUM = 0.9 # How much of past velocity to maintain in gradient update\n",
    "\n",
    "# LR Scheduler Hyperparams\n",
    "GAMMA = 0.9 # Multiplies previous LR by 0.1\n",
    "STEP_SIZE = 50000//BATCH_SIZE # Amount of steps before LR is decreased\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "world_size = torch.cuda.device_count()\n",
    "\n",
    "# In case we have zero cuda GPUs, no way to train the following\n",
    "if world_size < 1:\n",
    "    print(\"No Cuda Devices\")\n",
    "    exit()\n",
    "\n",
    "dataset_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download dataset if it is not present on the system\n",
    "DOWNLOAD_DATASET = False\n",
    "if 'testing' not in os.listdir():\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('testing')\n",
    "if 'dataset' not in os.listdir('testing'):\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('testing/dataset')\n",
    "    \n",
    "if 'training' not in os.listdir():\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('training')\n",
    "if 'dataset' not in os.listdir('training'):\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('training/dataset')\n",
    "\n",
    "training_data = datasets.CIFAR10(root=\"training/dataset/\", train=True, download=DOWNLOAD_DATASET, transform=dataset_transforms)\n",
    "testing_data = datasets.CIFAR10(root=\"training/dataset/\", train=False, download=DOWNLOAD_DATASET, transform=dataset_transforms)\n",
    "datal = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "TRAIN_SERIALIZED = False\n",
    "TRAIN_PIPELINE_PARALLEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaae4a0-0e30-43f5-b5c4-553e9a35446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SERIALIZED:\n",
    "    model = serialized_CNN_Model(2)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=SGD_MOMENTUM, nesterov=True)\n",
    "    \n",
    "    # LR Scheduler\n",
    "    learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "    \n",
    "    # Loss func\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    import tqdm\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for X, y in tqdm.tqdm(datal):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            prediction = model(X)\n",
    "            loss = criterion(prediction, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            learning_rate_scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        test_data_loader = DataLoader(testing_data, batch_size=BATCH_SIZE)\n",
    "        total_loss = 0\n",
    "        for X, y in test_data_loader:\n",
    "            \n",
    "            prediction = model(X)\n",
    "            loss = criterion(prediction, y)\n",
    "            total_loss += loss\n",
    "    \n",
    "        print(f'epoch {epoch} total loss: {total_loss}')\n",
    "\n",
    "    del model\n",
    "    del optimizer\n",
    "    del learning_rate_scheduler\n",
    "    del criterion\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a390620d-f863-4933-96f9-e43a48df1315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 256\n",
      "14 256\n",
      "14 128\n",
      "7 128\n",
      "7 256\n",
      "6 256\n",
      "9216 16834\n",
      "16834 512\n",
      "512 10\n",
      "cuda:0\n",
      "cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 80.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total loss: 1585.2926025390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 total loss: 1558.2706298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 81.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 total loss: 1360.1629638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 81.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 total loss: 1312.5411376953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 81.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 total loss: 1298.23974609375\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_PIPELINE_PARALLEL:\n",
    "    model = Pipeline_parallel_CNN_Model(2)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=SGD_MOMENTUM, nesterov=True)\n",
    "    \n",
    "    # LR Scheduler\n",
    "    learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "    \n",
    "    # Loss func\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    import tqdm\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for X, y in tqdm.tqdm(datal):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            prediction = model(X)\n",
    "            loss = criterion(prediction, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            learning_rate_scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        test_data_loader = DataLoader(testing_data, batch_size=BATCH_SIZE)\n",
    "        total_loss = 0\n",
    "        for X, y in test_data_loader:\n",
    "            \n",
    "            prediction = model(X)\n",
    "            loss = criterion(prediction, y)\n",
    "            total_loss += loss\n",
    "    \n",
    "        print(f'epoch {epoch} total loss: {total_loss}')\n",
    "\n",
    "    del model\n",
    "    del optimizer\n",
    "    del learning_rate_scheduler\n",
    "    del criterion\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b7f42b-09db-4e31-b5e0-e2b1dd5831cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 12:44:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              36W / 250W |  18046MiB / 32768MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   49C    P0              39W / 250W |   2840MiB / 32768MiB |     33%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     86101      C   ....conda/envs/rapids-24.08/bin/python    18042MiB |\n",
      "|    1   N/A  N/A     86101      C   ....conda/envs/rapids-24.08/bin/python     2836MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b3f54-8653-4698-bacf-3649932f3bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "rapids-24.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
