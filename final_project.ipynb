{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78599ade-681d-429b-a386-4a70f812a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecaf97f4-5785-4d47-b921-6f188c110a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  6 12:38:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              34W / 250W |  17214MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    114045      C   ....conda/envs/rapids-24.08/bin/python    17210MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5db8dcb-732b-40cb-874a-42960557aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_IMAGE_CHANNELS = 3\n",
    "INPUT_IMAGE_DIM = 32\n",
    "\n",
    "CONV_LAYER1_OUTPUT_CHANNELS = 256\n",
    "CONV_LAYER1_KERNEL_SIZE = 5\n",
    "CONV_LAYER1_STRIDE = 1\n",
    "CONV_LAYER1_PADDING = 0\n",
    "\n",
    "CONV_MAX_POOL_1_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_1_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_1_STRIDE_SIZE = 2\n",
    "\n",
    "CONV_LAYER2_OUTPUT_CHANNELS = 128\n",
    "CONV_LAYER2_KERNEL_SIZE = 5\n",
    "CONV_LAYER2_STRIDE = 1\n",
    "CONV_LAYER2_PADDING = 2\n",
    "\n",
    "CONV_MAX_POOL_2_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_2_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_2_STRIDE_SIZE = 2\n",
    "\n",
    "CONV_LAYER3_OUTPUT_CHANNELS = 256\n",
    "CONV_LAYER3_KERNEL_SIZE = 5\n",
    "CONV_LAYER3_STRIDE = 1\n",
    "CONV_LAYER3_PADDING = 1\n",
    "\n",
    "CONV_MAX_POOL_3_KERNEL_SIZE = 2\n",
    "CONV_MAX_POOL_3_PADDING_SIZE = 0\n",
    "CONV_MAX_POOL_3_STRIDE_SIZE = 1\n",
    "\n",
    "DROP_OUT_RATE = 0.25\n",
    "\n",
    "LINEAR_LAYER_1_OUTPUT_SIZE = 2048\n",
    "LINEAR_LAYER_2_OUTPUT_SIZE = 512\n",
    "\n",
    "# NUMBER OF CLASSES\n",
    "LINEAR_LAYER_3_OUTPUT_SIZE = 10 # 10 for the amount of classes that are in the dataset\n",
    "\n",
    "\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_gpus):\n",
    "        super(CNN_Model, self).__init__()\n",
    "\n",
    "        # CONV2D LAYER1 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer1 = nn.Conv2d(INPUT_IMAGE_CHANNELS, CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER1_KERNEL_SIZE, CONV_LAYER1_STRIDE, CONV_LAYER1_PADDING)\n",
    "        self.image_dimension = (INPUT_IMAGE_DIM - ((CONV_LAYER1_KERNEL_SIZE) - (2 * CONV_LAYER1_PADDING)))//CONV_LAYER1_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER1_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 1, Change in image dimensions\n",
    "        self.maxPooling1 = nn.MaxPool2d(CONV_MAX_POOL_1_KERNEL_SIZE, CONV_MAX_POOL_1_STRIDE_SIZE, CONV_MAX_POOL_1_PADDING_SIZE)\n",
    "        self.dropout1 = nn.Dropout(DROP_OUT_RATE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_1_KERNEL_SIZE) - (2 * CONV_MAX_POOL_1_PADDING_SIZE)))//CONV_MAX_POOL_1_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        \n",
    "        \n",
    "        # CONV2D LAYER2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer2 = nn.Conv2d(CONV_LAYER1_OUTPUT_CHANNELS, CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER2_KERNEL_SIZE, CONV_LAYER2_STRIDE, CONV_LAYER2_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER2_KERNEL_SIZE) - (2 * CONV_LAYER2_PADDING)))//CONV_LAYER2_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER2_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "        # MAX POOLING LAYER 2 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.maxPooling2 = nn.MaxPool2d(CONV_MAX_POOL_2_KERNEL_SIZE, CONV_MAX_POOL_2_STRIDE_SIZE, CONV_MAX_POOL_2_PADDING_SIZE)\n",
    "        self.dropout2 = nn.Dropout(DROP_OUT_RATE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_2_KERNEL_SIZE) - (2 * CONV_MAX_POOL_2_PADDING_SIZE)))//CONV_MAX_POOL_2_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "        # CONV2D LAYER 3 AND CHANGE IN IMAGE DIMENSIONS\n",
    "        self.conv_layer3 = nn.Conv2d(CONV_LAYER2_OUTPUT_CHANNELS, CONV_LAYER3_OUTPUT_CHANNELS, CONV_LAYER3_KERNEL_SIZE, CONV_LAYER3_STRIDE, CONV_LAYER3_PADDING)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_LAYER3_KERNEL_SIZE) - (2 * CONV_LAYER3_PADDING)))//CONV_LAYER3_STRIDE + 1\n",
    "        self.image_channel_size = CONV_LAYER3_OUTPUT_CHANNELS\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "        \n",
    "\n",
    "        # MAX POOLING LAYER 3 AND CHANGE IN IIMAGE DIMENSIONS\n",
    "        self.maxPooling3 = nn.MaxPool2d(CONV_MAX_POOL_3_KERNEL_SIZE, CONV_MAX_POOL_3_STRIDE_SIZE, CONV_MAX_POOL_3_PADDING_SIZE)\n",
    "        self.dropout3 = nn.Dropout(DROP_OUT_RATE)\n",
    "        self.image_dimension = (self.image_dimension - ((CONV_MAX_POOL_3_KERNEL_SIZE) - (2 * CONV_MAX_POOL_3_PADDING_SIZE)))//CONV_MAX_POOL_3_STRIDE_SIZE + 1\n",
    "        print(self.image_dimension, self.image_channel_size)\n",
    "\n",
    "\n",
    "\n",
    "        # Since we flatten the image after the CONV2D Layers, we need to calculate the size of the feature\n",
    "        # Vector going into the nn.Linear layer\n",
    "        self.fc1_input_size = self.image_dimension * self.image_dimension * self.image_channel_size\n",
    "        \n",
    "        # Fully connected Layers\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        self.dropout4 = nn.Dropout(DROP_OUT_RATE)\n",
    "        print(self.fc1_input_size, LINEAR_LAYER_1_OUTPUT_SIZE)\n",
    "        \n",
    "        self.fc2 = nn.Linear(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "        self.dropout5 = nn.Dropout(DROP_OUT_RATE)\n",
    "        print(LINEAR_LAYER_1_OUTPUT_SIZE, LINEAR_LAYER_2_OUTPUT_SIZE)\n",
    "\n",
    "        \n",
    "        self.fc3 = nn.Linear(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "        print(LINEAR_LAYER_2_OUTPUT_SIZE, LINEAR_LAYER_3_OUTPUT_SIZE)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.maxPooling1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.maxPooling2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.maxPooling3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9c323a-9577-478c-9da4-6d3b3bbc740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 256\n",
      "14 256\n",
      "14 128\n",
      "7 128\n",
      "5 256\n",
      "4 256\n",
      "4096 2048\n",
      "2048 512\n",
      "512 10\n"
     ]
    }
   ],
   "source": [
    "# Training Hyperparams\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "# Optimizer Hyperparams\n",
    "LEARNING_RATE = 10e-3\n",
    "SGD_MOMENTUM = 0.9 # How much of past velocity to maintain in gradient update\n",
    "\n",
    "# LR Scheduler Hyperparams\n",
    "GAMMA = 0.1 # Multiplies previous LR by 0.1\n",
    "STEP_SIZE = 3000 # Amount of steps before LR is decreased\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "world_size = torch.cuda.device_count()\n",
    "\n",
    "# In case we have zero cuda GPUs, no way to train the following\n",
    "if world_size < 1:\n",
    "    print(\"No Cuda Devices\")\n",
    "    exit()\n",
    "\n",
    "dataset_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download dataset if it is not present on the system\n",
    "DOWNLOAD_DATASET = False\n",
    "if 'testing' not in os.listdir():\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('testing')\n",
    "if 'dataset' not in os.listdir('testing'):\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('testing/dataset')\n",
    "    \n",
    "if 'training' not in os.listdir():\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('training')\n",
    "if 'dataset' not in os.listdir('training'):\n",
    "    DOWNLOAD_DATASET = True\n",
    "    os.mkdir('training/dataset')\n",
    "training_data = datasets.CIFAR10(root=\"training/dataset/\", train=True, download=DOWNLOAD_DATASET, transform=dataset_transforms)\n",
    "testing_data = datasets.CIFAR10(root=\"training/dataset/\", train=False, download=DOWNLOAD_DATASET, transform=dataset_transforms)\n",
    "datal = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = CNN_Model(25)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=SGD_MOMENTUM, nesterov=True)\n",
    "\n",
    "# LR Scheduler\n",
    "learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "# Loss func\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a390620d-f863-4933-96f9-e43a48df1315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/tmp/SLURM_27136739/ipykernel_114045/4022028634.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(datapoint[0])\n",
      "/tmp/SLURM_27136739/ipykernel_114045/4022028634.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(datapoint[1])\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 241.87it/s]\n",
      "/tmp/SLURM_27136739/ipykernel_114045/4022028634.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(point[0])\n",
      "/tmp/SLURM_27136739/ipykernel_114045/4022028634.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(point[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total loss: 1280.2471923828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 244.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 total loss: 1135.51611328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 243.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 total loss: 1131.6202392578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 242.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 total loss: 1131.4256591796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 243.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 total loss: 1131.42138671875\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for datapoint in tqdm.tqdm(datal):\n",
    "        X = torch.tensor(datapoint[0])\n",
    "        y = torch.tensor(datapoint[1])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        prediction = model(X.to(device))\n",
    "        loss = criterion(prediction, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        learning_rate_scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_data_loader = DataLoader(testing_data, batch_size=BATCH_SIZE)\n",
    "    total_loss = 0\n",
    "    for point in test_data_loader:\n",
    "        X = torch.tensor(point[0])\n",
    "        y = torch.tensor(point[1])\n",
    "        prediction = model(X.to(device))\n",
    "        loss = criterion(prediction, y.to(device))\n",
    "        total_loss += loss\n",
    "\n",
    "    print(f'epoch {epoch} total loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bedaa5-1cc0-4e81-ae53-f981e7980ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "rapids-24.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
